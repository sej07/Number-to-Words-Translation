{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25849796-f40f-4bba-a9ba-1fa7c979744c",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f0363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f744a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd7d66-a6f3-458b-add7-5f067f4ca34d",
   "metadata": {},
   "source": [
    "### Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb4f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe32fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"number_to_words_dataset.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e426e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"input\", \"target\"])\n",
    "    \n",
    "    for i in range(start, end + 1):\n",
    "        number = str(i)\n",
    "        words = num2words(i).replace('-', ' ').replace(',', '')  \n",
    "        writer.writerow([number, words.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "950d40b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   input target\n",
      "0      0   zero\n",
      "1      1    one\n",
      "2      2    two\n",
      "3      3  three\n",
      "4      4   four\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('number_to_words_dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4f950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df['input'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d0bba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df['target'].astype(str).str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41841ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '153',\n",
       " '154',\n",
       " '155',\n",
       " '156',\n",
       " '157',\n",
       " '158',\n",
       " '159',\n",
       " '160',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '164',\n",
       " '165',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '169',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '173',\n",
       " '174',\n",
       " '175',\n",
       " '176',\n",
       " '177',\n",
       " '178',\n",
       " '179',\n",
       " '180',\n",
       " '181',\n",
       " '182',\n",
       " '183',\n",
       " '184',\n",
       " '185',\n",
       " '186',\n",
       " '187',\n",
       " '188',\n",
       " '189',\n",
       " '190',\n",
       " '191',\n",
       " '192',\n",
       " '193',\n",
       " '194',\n",
       " '195',\n",
       " '196',\n",
       " '197',\n",
       " '198',\n",
       " '199',\n",
       " '200',\n",
       " '201',\n",
       " '202',\n",
       " '203',\n",
       " '204',\n",
       " '205',\n",
       " '206',\n",
       " '207',\n",
       " '208',\n",
       " '209',\n",
       " '210',\n",
       " '211',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '216',\n",
       " '217',\n",
       " '218',\n",
       " '219',\n",
       " '220',\n",
       " '221',\n",
       " '222',\n",
       " '223',\n",
       " '224',\n",
       " '225',\n",
       " '226',\n",
       " '227',\n",
       " '228',\n",
       " '229',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '234',\n",
       " '235',\n",
       " '236',\n",
       " '237',\n",
       " '238',\n",
       " '239',\n",
       " '240',\n",
       " '241',\n",
       " '242',\n",
       " '243',\n",
       " '244',\n",
       " '245',\n",
       " '246',\n",
       " '247',\n",
       " '248',\n",
       " '249',\n",
       " '250',\n",
       " '251',\n",
       " '252',\n",
       " '253',\n",
       " '254',\n",
       " '255',\n",
       " '256',\n",
       " '257',\n",
       " '258',\n",
       " '259',\n",
       " '260',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '264',\n",
       " '265',\n",
       " '266',\n",
       " '267',\n",
       " '268',\n",
       " '269',\n",
       " '270',\n",
       " '271',\n",
       " '272',\n",
       " '273',\n",
       " '274',\n",
       " '275',\n",
       " '276',\n",
       " '277',\n",
       " '278',\n",
       " '279',\n",
       " '280',\n",
       " '281',\n",
       " '282',\n",
       " '283',\n",
       " '284',\n",
       " '285',\n",
       " '286',\n",
       " '287',\n",
       " '288',\n",
       " '289',\n",
       " '290',\n",
       " '291',\n",
       " '292',\n",
       " '293',\n",
       " '294',\n",
       " '295',\n",
       " '296',\n",
       " '297',\n",
       " '298',\n",
       " '299']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491ce492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'eleven',\n",
       " 'twelve',\n",
       " 'thirteen',\n",
       " 'fourteen',\n",
       " 'fifteen',\n",
       " 'sixteen',\n",
       " 'seventeen',\n",
       " 'eighteen',\n",
       " 'nineteen',\n",
       " 'twenty',\n",
       " 'twenty one',\n",
       " 'twenty two',\n",
       " 'twenty three',\n",
       " 'twenty four',\n",
       " 'twenty five',\n",
       " 'twenty six',\n",
       " 'twenty seven',\n",
       " 'twenty eight',\n",
       " 'twenty nine',\n",
       " 'thirty',\n",
       " 'thirty one',\n",
       " 'thirty two',\n",
       " 'thirty three',\n",
       " 'thirty four',\n",
       " 'thirty five',\n",
       " 'thirty six',\n",
       " 'thirty seven',\n",
       " 'thirty eight',\n",
       " 'thirty nine',\n",
       " 'forty',\n",
       " 'forty one',\n",
       " 'forty two',\n",
       " 'forty three',\n",
       " 'forty four',\n",
       " 'forty five',\n",
       " 'forty six',\n",
       " 'forty seven',\n",
       " 'forty eight',\n",
       " 'forty nine',\n",
       " 'fifty',\n",
       " 'fifty one',\n",
       " 'fifty two',\n",
       " 'fifty three',\n",
       " 'fifty four',\n",
       " 'fifty five',\n",
       " 'fifty six',\n",
       " 'fifty seven',\n",
       " 'fifty eight',\n",
       " 'fifty nine',\n",
       " 'sixty',\n",
       " 'sixty one',\n",
       " 'sixty two',\n",
       " 'sixty three',\n",
       " 'sixty four',\n",
       " 'sixty five',\n",
       " 'sixty six',\n",
       " 'sixty seven',\n",
       " 'sixty eight',\n",
       " 'sixty nine',\n",
       " 'seventy',\n",
       " 'seventy one',\n",
       " 'seventy two',\n",
       " 'seventy three',\n",
       " 'seventy four',\n",
       " 'seventy five',\n",
       " 'seventy six',\n",
       " 'seventy seven',\n",
       " 'seventy eight',\n",
       " 'seventy nine',\n",
       " 'eighty',\n",
       " 'eighty one',\n",
       " 'eighty two',\n",
       " 'eighty three',\n",
       " 'eighty four',\n",
       " 'eighty five',\n",
       " 'eighty six',\n",
       " 'eighty seven',\n",
       " 'eighty eight',\n",
       " 'eighty nine',\n",
       " 'ninety',\n",
       " 'ninety one',\n",
       " 'ninety two',\n",
       " 'ninety three',\n",
       " 'ninety four',\n",
       " 'ninety five',\n",
       " 'ninety six',\n",
       " 'ninety seven',\n",
       " 'ninety eight',\n",
       " 'ninety nine',\n",
       " 'one hundred',\n",
       " 'one hundred and one',\n",
       " 'one hundred and two',\n",
       " 'one hundred and three',\n",
       " 'one hundred and four',\n",
       " 'one hundred and five',\n",
       " 'one hundred and six',\n",
       " 'one hundred and seven',\n",
       " 'one hundred and eight',\n",
       " 'one hundred and nine',\n",
       " 'one hundred and ten',\n",
       " 'one hundred and eleven',\n",
       " 'one hundred and twelve',\n",
       " 'one hundred and thirteen',\n",
       " 'one hundred and fourteen',\n",
       " 'one hundred and fifteen',\n",
       " 'one hundred and sixteen',\n",
       " 'one hundred and seventeen',\n",
       " 'one hundred and eighteen',\n",
       " 'one hundred and nineteen',\n",
       " 'one hundred and twenty',\n",
       " 'one hundred and twenty one',\n",
       " 'one hundred and twenty two',\n",
       " 'one hundred and twenty three',\n",
       " 'one hundred and twenty four',\n",
       " 'one hundred and twenty five',\n",
       " 'one hundred and twenty six',\n",
       " 'one hundred and twenty seven',\n",
       " 'one hundred and twenty eight',\n",
       " 'one hundred and twenty nine',\n",
       " 'one hundred and thirty',\n",
       " 'one hundred and thirty one',\n",
       " 'one hundred and thirty two',\n",
       " 'one hundred and thirty three',\n",
       " 'one hundred and thirty four',\n",
       " 'one hundred and thirty five',\n",
       " 'one hundred and thirty six',\n",
       " 'one hundred and thirty seven',\n",
       " 'one hundred and thirty eight',\n",
       " 'one hundred and thirty nine',\n",
       " 'one hundred and forty',\n",
       " 'one hundred and forty one',\n",
       " 'one hundred and forty two',\n",
       " 'one hundred and forty three',\n",
       " 'one hundred and forty four',\n",
       " 'one hundred and forty five',\n",
       " 'one hundred and forty six',\n",
       " 'one hundred and forty seven',\n",
       " 'one hundred and forty eight',\n",
       " 'one hundred and forty nine',\n",
       " 'one hundred and fifty',\n",
       " 'one hundred and fifty one',\n",
       " 'one hundred and fifty two',\n",
       " 'one hundred and fifty three',\n",
       " 'one hundred and fifty four',\n",
       " 'one hundred and fifty five',\n",
       " 'one hundred and fifty six',\n",
       " 'one hundred and fifty seven',\n",
       " 'one hundred and fifty eight',\n",
       " 'one hundred and fifty nine',\n",
       " 'one hundred and sixty',\n",
       " 'one hundred and sixty one',\n",
       " 'one hundred and sixty two',\n",
       " 'one hundred and sixty three',\n",
       " 'one hundred and sixty four',\n",
       " 'one hundred and sixty five',\n",
       " 'one hundred and sixty six',\n",
       " 'one hundred and sixty seven',\n",
       " 'one hundred and sixty eight',\n",
       " 'one hundred and sixty nine',\n",
       " 'one hundred and seventy',\n",
       " 'one hundred and seventy one',\n",
       " 'one hundred and seventy two',\n",
       " 'one hundred and seventy three',\n",
       " 'one hundred and seventy four',\n",
       " 'one hundred and seventy five',\n",
       " 'one hundred and seventy six',\n",
       " 'one hundred and seventy seven',\n",
       " 'one hundred and seventy eight',\n",
       " 'one hundred and seventy nine',\n",
       " 'one hundred and eighty',\n",
       " 'one hundred and eighty one',\n",
       " 'one hundred and eighty two',\n",
       " 'one hundred and eighty three',\n",
       " 'one hundred and eighty four',\n",
       " 'one hundred and eighty five',\n",
       " 'one hundred and eighty six',\n",
       " 'one hundred and eighty seven',\n",
       " 'one hundred and eighty eight',\n",
       " 'one hundred and eighty nine',\n",
       " 'one hundred and ninety',\n",
       " 'one hundred and ninety one',\n",
       " 'one hundred and ninety two',\n",
       " 'one hundred and ninety three',\n",
       " 'one hundred and ninety four',\n",
       " 'one hundred and ninety five',\n",
       " 'one hundred and ninety six',\n",
       " 'one hundred and ninety seven',\n",
       " 'one hundred and ninety eight',\n",
       " 'one hundred and ninety nine',\n",
       " 'two hundred',\n",
       " 'two hundred and one',\n",
       " 'two hundred and two',\n",
       " 'two hundred and three',\n",
       " 'two hundred and four',\n",
       " 'two hundred and five',\n",
       " 'two hundred and six',\n",
       " 'two hundred and seven',\n",
       " 'two hundred and eight',\n",
       " 'two hundred and nine',\n",
       " 'two hundred and ten',\n",
       " 'two hundred and eleven',\n",
       " 'two hundred and twelve',\n",
       " 'two hundred and thirteen',\n",
       " 'two hundred and fourteen',\n",
       " 'two hundred and fifteen',\n",
       " 'two hundred and sixteen',\n",
       " 'two hundred and seventeen',\n",
       " 'two hundred and eighteen',\n",
       " 'two hundred and nineteen',\n",
       " 'two hundred and twenty',\n",
       " 'two hundred and twenty one',\n",
       " 'two hundred and twenty two',\n",
       " 'two hundred and twenty three',\n",
       " 'two hundred and twenty four',\n",
       " 'two hundred and twenty five',\n",
       " 'two hundred and twenty six',\n",
       " 'two hundred and twenty seven',\n",
       " 'two hundred and twenty eight',\n",
       " 'two hundred and twenty nine',\n",
       " 'two hundred and thirty',\n",
       " 'two hundred and thirty one',\n",
       " 'two hundred and thirty two',\n",
       " 'two hundred and thirty three',\n",
       " 'two hundred and thirty four',\n",
       " 'two hundred and thirty five',\n",
       " 'two hundred and thirty six',\n",
       " 'two hundred and thirty seven',\n",
       " 'two hundred and thirty eight',\n",
       " 'two hundred and thirty nine',\n",
       " 'two hundred and forty',\n",
       " 'two hundred and forty one',\n",
       " 'two hundred and forty two',\n",
       " 'two hundred and forty three',\n",
       " 'two hundred and forty four',\n",
       " 'two hundred and forty five',\n",
       " 'two hundred and forty six',\n",
       " 'two hundred and forty seven',\n",
       " 'two hundred and forty eight',\n",
       " 'two hundred and forty nine',\n",
       " 'two hundred and fifty',\n",
       " 'two hundred and fifty one',\n",
       " 'two hundred and fifty two',\n",
       " 'two hundred and fifty three',\n",
       " 'two hundred and fifty four',\n",
       " 'two hundred and fifty five',\n",
       " 'two hundred and fifty six',\n",
       " 'two hundred and fifty seven',\n",
       " 'two hundred and fifty eight',\n",
       " 'two hundred and fifty nine',\n",
       " 'two hundred and sixty',\n",
       " 'two hundred and sixty one',\n",
       " 'two hundred and sixty two',\n",
       " 'two hundred and sixty three',\n",
       " 'two hundred and sixty four',\n",
       " 'two hundred and sixty five',\n",
       " 'two hundred and sixty six',\n",
       " 'two hundred and sixty seven',\n",
       " 'two hundred and sixty eight',\n",
       " 'two hundred and sixty nine',\n",
       " 'two hundred and seventy',\n",
       " 'two hundred and seventy one',\n",
       " 'two hundred and seventy two',\n",
       " 'two hundred and seventy three',\n",
       " 'two hundred and seventy four',\n",
       " 'two hundred and seventy five',\n",
       " 'two hundred and seventy six',\n",
       " 'two hundred and seventy seven',\n",
       " 'two hundred and seventy eight',\n",
       " 'two hundred and seventy nine',\n",
       " 'two hundred and eighty',\n",
       " 'two hundred and eighty one',\n",
       " 'two hundred and eighty two',\n",
       " 'two hundred and eighty three',\n",
       " 'two hundred and eighty four',\n",
       " 'two hundred and eighty five',\n",
       " 'two hundred and eighty six',\n",
       " 'two hundred and eighty seven',\n",
       " 'two hundred and eighty eight',\n",
       " 'two hundred and eighty nine',\n",
       " 'two hundred and ninety',\n",
       " 'two hundred and ninety one',\n",
       " 'two hundred and ninety two',\n",
       " 'two hundred and ninety three',\n",
       " 'two hundred and ninety four',\n",
       " 'two hundred and ninety five',\n",
       " 'two hundred and ninety six',\n",
       " 'two hundred and ninety seven',\n",
       " 'two hundred and ninety eight',\n",
       " 'two hundred and ninety nine']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723f59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_input = ['<sos> ' + t for t in targets]\n",
    "targets_output = [t + ' <eos>' for t in targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cca9cec-1cce-4391-9023-ebaaf874c2e6",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e57d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\Downloads\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92305bb9-e895-4416-a709-10bbfeeca45b",
   "metadata": {},
   "source": [
    "### Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a813c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = Tokenizer(char_level=True, filters='')\n",
    "input_tokenizer.fit_on_texts(inputs)\n",
    "encoder_input_seq = input_tokenizer.texts_to_sequences(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c9194ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokenizer = Tokenizer(char_level=False, lower=True, filters='')\n",
    "target_tokenizer.fit_on_texts(targets_input + targets_output)\n",
    "decoder_input_seq = target_tokenizer.texts_to_sequences(targets_input)\n",
    "decoder_target_seq = target_tokenizer.texts_to_sequences(targets_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2252c7-6427-45e2-ad92-af1ab81df30a",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3da3265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max(len(seq) for seq in encoder_input_seq)\n",
    "max_decoder_seq_length = max(len(seq) for seq in decoder_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65e713e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_seq = pad_sequences(encoder_input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "decoder_input_seq = pad_sequences(decoder_input_seq, maxlen=max_decoder_seq_length, padding='post')\n",
    "decoder_target_seq = pad_sequences(decoder_target_seq, maxlen=max_decoder_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0a4a945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: (300, 3)\n",
      "Decoder input shape: (300, 6)\n",
      "Decoder target shape: (300, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder input shape:\", encoder_input_seq.shape)\n",
    "print(\"Decoder input shape:\", decoder_input_seq.shape)\n",
    "print(\"Decoder target shape:\", decoder_target_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5023e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input dtype: int32\n",
      "Decoder input dtype: int32\n",
      "Decoder target dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder input dtype:\", encoder_input_seq.dtype)\n",
    "print(\"Decoder input dtype:\", decoder_input_seq.dtype)\n",
    "print(\"Decoder target dtype:\", decoder_target_seq.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afb40abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e12ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3956c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "lstm_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf4114-6bbf-4bb3-a16a-190f0bae6ef3",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "faf3d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
    "encoder_embedding = Embedding(input_dim=encoder_vocab_size, output_dim=embedding_dim, name='encoder_embedding')(encoder_inputs)\n",
    "encoder_lstm1, state_h1, state_c1 = LSTM(lstm_units, return_sequences=True, return_state=True, name='encoder_lstm1')(encoder_embedding)\n",
    "encoder_lstm2, state_h2, state_c2 = LSTM(lstm_units, return_state=True, name='encoder_lstm2')(encoder_lstm1)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0439a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
    "decoder_embedding = Embedding(input_dim=decoder_vocab_size, output_dim=embedding_dim, name='decoder_embedding')(decoder_inputs)\n",
    "decoder_lstm1 = LSTM(lstm_units, return_sequences=True, return_state=True, name='decoder_lstm1')\n",
    "decoder_output1, _, _ = decoder_lstm1(decoder_embedding, initial_state=[state_h2, state_c2])\n",
    "\n",
    "# Second LSTM builds deeper context\n",
    "decoder_lstm2 = LSTM(lstm_units, return_sequences=True, return_state=True, name='decoder_lstm2')\n",
    "decoder_outputs, _, _ = decoder_lstm2(decoder_output1)\n",
    "\n",
    "# Final Dense layer\n",
    "decoder_dense = Dense(decoder_vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5834c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1b1ca8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_embedding (Embeddi  (None, None, 64)             704       ['encoder_inputs[0][0]']      \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " encoder_lstm1 (LSTM)        [(None, None, 128),          98816     ['encoder_embedding[0][0]']   \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " decoder_embedding (Embeddi  (None, None, 64)             2112      ['decoder_inputs[0][0]']      \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_lstm2 (LSTM)        [(None, 128),                131584    ['encoder_lstm1[0][0]']       \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " decoder_lstm1 (LSTM)        [(None, None, 128),          98816     ['decoder_embedding[0][0]',   \n",
      "                              (None, 128),                           'encoder_lstm2[0][1]',       \n",
      "                              (None, 128)]                           'encoder_lstm2[0][2]']       \n",
      "                                                                                                  \n",
      " decoder_lstm2 (LSTM)        [(None, None, 128),          131584    ['decoder_lstm1[0][0]']       \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)       (None, None, 33)             4257      ['decoder_lstm2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 467873 (1.78 MB)\n",
      "Trainable params: 467873 (1.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5d6bdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8bf1bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target_seq = np.expand_dims(decoder_target_seq, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2764818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder shape: (300, 3)\n",
      "Decoder input shape: (300, 6)\n",
      "Decoder target shape: (300, 6, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder shape:\", encoder_input_seq.shape)\n",
    "print(\"Decoder input shape:\", decoder_input_seq.shape)\n",
    "print(\"Decoder target shape:\", decoder_target_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9a424-6cf5-41ff-80f8-4387c9583149",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5674bc59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4902 - accuracy: 0.1306 - val_loss: 0.7735 - val_accuracy: 0.1205\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4787 - accuracy: 0.1327 - val_loss: 0.7645 - val_accuracy: 0.1197\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4772 - accuracy: 0.1332 - val_loss: 0.7637 - val_accuracy: 0.1220\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4716 - accuracy: 0.1300 - val_loss: 0.7453 - val_accuracy: 0.1188\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4638 - accuracy: 0.1310 - val_loss: 0.7376 - val_accuracy: 0.1166\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4541 - accuracy: 0.1335 - val_loss: 0.7755 - val_accuracy: 0.1196\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4513 - accuracy: 0.1299 - val_loss: 0.7685 - val_accuracy: 0.1192\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4461 - accuracy: 0.1329 - val_loss: 0.7537 - val_accuracy: 0.1183\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4429 - accuracy: 0.1303 - val_loss: 0.8032 - val_accuracy: 0.1190\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4397 - accuracy: 0.1300 - val_loss: 0.7531 - val_accuracy: 0.1182\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4308 - accuracy: 0.1301 - val_loss: 0.7346 - val_accuracy: 0.1194\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4406 - accuracy: 0.1309 - val_loss: 0.8302 - val_accuracy: 0.1200\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4488 - accuracy: 0.1304 - val_loss: 0.7540 - val_accuracy: 0.1192\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.4272 - accuracy: 0.1298 - val_loss: 0.7658 - val_accuracy: 0.1180\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4196 - accuracy: 0.1313 - val_loss: 0.7571 - val_accuracy: 0.1179\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4111 - accuracy: 0.1303 - val_loss: 0.7436 - val_accuracy: 0.1199\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4057 - accuracy: 0.1298 - val_loss: 0.7453 - val_accuracy: 0.1198\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4078 - accuracy: 0.1308 - val_loss: 0.7792 - val_accuracy: 0.1201\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4207 - accuracy: 0.1300 - val_loss: 0.7727 - val_accuracy: 0.1184\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4426 - accuracy: 0.1302 - val_loss: 0.7567 - val_accuracy: 0.1213\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4179 - accuracy: 0.1310 - val_loss: 0.7650 - val_accuracy: 0.1227\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.4107 - accuracy: 0.1313 - val_loss: 0.7557 - val_accuracy: 0.1212\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4273 - accuracy: 0.1299 - val_loss: 0.7738 - val_accuracy: 0.1212\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.4333 - accuracy: 0.1312 - val_loss: 0.7775 - val_accuracy: 0.1222\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4220 - accuracy: 0.1306 - val_loss: 0.8226 - val_accuracy: 0.1214\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3979 - accuracy: 0.1313 - val_loss: 0.7350 - val_accuracy: 0.1213\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3844 - accuracy: 0.1291 - val_loss: 0.7357 - val_accuracy: 0.1193\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3813 - accuracy: 0.1312 - val_loss: 0.7522 - val_accuracy: 0.1192\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3736 - accuracy: 0.1308 - val_loss: 0.7657 - val_accuracy: 0.1190\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3670 - accuracy: 0.1305 - val_loss: 0.7383 - val_accuracy: 0.1194\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3656 - accuracy: 0.1294 - val_loss: 0.7412 - val_accuracy: 0.1184\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3608 - accuracy: 0.1305 - val_loss: 0.7752 - val_accuracy: 0.1198\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3550 - accuracy: 0.1304 - val_loss: 0.7530 - val_accuracy: 0.1198\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3501 - accuracy: 0.1306 - val_loss: 0.7168 - val_accuracy: 0.1190\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3440 - accuracy: 0.1312 - val_loss: 0.7420 - val_accuracy: 0.1194\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3403 - accuracy: 0.1305 - val_loss: 0.7494 - val_accuracy: 0.1194\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3342 - accuracy: 0.1305 - val_loss: 0.7081 - val_accuracy: 0.1208\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3304 - accuracy: 0.1328 - val_loss: 0.7081 - val_accuracy: 0.1208\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3295 - accuracy: 0.1299 - val_loss: 0.7348 - val_accuracy: 0.1198\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.3269 - accuracy: 0.1322 - val_loss: 0.7353 - val_accuracy: 0.1192\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3232 - accuracy: 0.1298 - val_loss: 0.7116 - val_accuracy: 0.1203\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3167 - accuracy: 0.1302 - val_loss: 0.7376 - val_accuracy: 0.1200\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3145 - accuracy: 0.1312 - val_loss: 0.7068 - val_accuracy: 0.1208\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3171 - accuracy: 0.1342 - val_loss: 0.7286 - val_accuracy: 0.1205\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3210 - accuracy: 0.1299 - val_loss: 0.6948 - val_accuracy: 0.1223\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3092 - accuracy: 0.1315 - val_loss: 0.6840 - val_accuracy: 0.1193\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3062 - accuracy: 0.1327 - val_loss: 0.7637 - val_accuracy: 0.1224\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3129 - accuracy: 0.1295 - val_loss: 0.7093 - val_accuracy: 0.1225\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3054 - accuracy: 0.1302 - val_loss: 0.8136 - val_accuracy: 0.1258\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3405 - accuracy: 0.1316 - val_loss: 0.6828 - val_accuracy: 0.1202\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.3152 - accuracy: 0.1307 - val_loss: 0.7356 - val_accuracy: 0.1215\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3328 - accuracy: 0.1309 - val_loss: 0.6705 - val_accuracy: 0.1235\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3105 - accuracy: 0.1308 - val_loss: 0.6761 - val_accuracy: 0.1224\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2984 - accuracy: 0.1301 - val_loss: 0.7368 - val_accuracy: 0.1213\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2983 - accuracy: 0.1304 - val_loss: 0.6632 - val_accuracy: 0.1205\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2873 - accuracy: 0.1305 - val_loss: 0.6507 - val_accuracy: 0.1202\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2815 - accuracy: 0.1324 - val_loss: 0.6588 - val_accuracy: 0.1202\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2700 - accuracy: 0.1308 - val_loss: 0.6598 - val_accuracy: 0.1207\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2695 - accuracy: 0.1308 - val_loss: 0.6269 - val_accuracy: 0.1210\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.2621 - accuracy: 0.1301 - val_loss: 0.6443 - val_accuracy: 0.1206\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2624 - accuracy: 0.1327 - val_loss: 0.6300 - val_accuracy: 0.1207\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2557 - accuracy: 0.1309 - val_loss: 0.5951 - val_accuracy: 0.1201\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2531 - accuracy: 0.1305 - val_loss: 0.6194 - val_accuracy: 0.1212\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2448 - accuracy: 0.1313 - val_loss: 0.6487 - val_accuracy: 0.1194\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2407 - accuracy: 0.1316 - val_loss: 0.6177 - val_accuracy: 0.1206\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2378 - accuracy: 0.1324 - val_loss: 0.5990 - val_accuracy: 0.1206\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2376 - accuracy: 0.1297 - val_loss: 0.6325 - val_accuracy: 0.1207\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2332 - accuracy: 0.1305 - val_loss: 0.6073 - val_accuracy: 0.1202\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2272 - accuracy: 0.1301 - val_loss: 0.6027 - val_accuracy: 0.1202\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2235 - accuracy: 0.1299 - val_loss: 0.6101 - val_accuracy: 0.1198\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2299 - accuracy: 0.1312 - val_loss: 0.6048 - val_accuracy: 0.1226\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2390 - accuracy: 0.1339 - val_loss: 0.6037 - val_accuracy: 0.1221\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2451 - accuracy: 0.1303 - val_loss: 0.7059 - val_accuracy: 0.1231\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2443 - accuracy: 0.1298 - val_loss: 0.6191 - val_accuracy: 0.1208\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2293 - accuracy: 0.1323 - val_loss: 0.6075 - val_accuracy: 0.1212\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2377 - accuracy: 0.1308 - val_loss: 0.5892 - val_accuracy: 0.1203\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2332 - accuracy: 0.1306 - val_loss: 0.5919 - val_accuracy: 0.1214\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2495 - accuracy: 0.1324 - val_loss: 0.5976 - val_accuracy: 0.1211\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2402 - accuracy: 0.1297 - val_loss: 0.6919 - val_accuracy: 0.1204\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2400 - accuracy: 0.1313 - val_loss: 0.6062 - val_accuracy: 0.1204\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.2317 - accuracy: 0.1311 - val_loss: 0.6646 - val_accuracy: 0.1212\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2215 - accuracy: 0.1321 - val_loss: 0.6233 - val_accuracy: 0.1209\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2270 - accuracy: 0.1298 - val_loss: 0.6215 - val_accuracy: 0.1189\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2238 - accuracy: 0.1331 - val_loss: 0.6015 - val_accuracy: 0.1190\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2145 - accuracy: 0.1297 - val_loss: 0.5936 - val_accuracy: 0.1200\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2044 - accuracy: 0.1292 - val_loss: 0.5751 - val_accuracy: 0.1203\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1932 - accuracy: 0.1314 - val_loss: 0.6203 - val_accuracy: 0.1211\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1878 - accuracy: 0.1314 - val_loss: 0.6219 - val_accuracy: 0.1211\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1898 - accuracy: 0.1308 - val_loss: 0.6210 - val_accuracy: 0.1218\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1800 - accuracy: 0.1303 - val_loss: 0.5907 - val_accuracy: 0.1215\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1761 - accuracy: 0.1321 - val_loss: 0.5863 - val_accuracy: 0.1213\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1708 - accuracy: 0.1300 - val_loss: 0.5663 - val_accuracy: 0.1207\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1687 - accuracy: 0.1309 - val_loss: 0.5870 - val_accuracy: 0.1211\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1675 - accuracy: 0.1302 - val_loss: 0.5844 - val_accuracy: 0.1221\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1622 - accuracy: 0.1311 - val_loss: 0.5925 - val_accuracy: 0.1230\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1596 - accuracy: 0.1302 - val_loss: 0.5794 - val_accuracy: 0.1216\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.1576 - accuracy: 0.1320 - val_loss: 0.5924 - val_accuracy: 0.1220\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1550 - accuracy: 0.1305 - val_loss: 0.5820 - val_accuracy: 0.1216\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1512 - accuracy: 0.1293 - val_loss: 0.5770 - val_accuracy: 0.1213\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1496 - accuracy: 0.1300 - val_loss: 0.5669 - val_accuracy: 0.1213\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1470 - accuracy: 0.1303 - val_loss: 0.5742 - val_accuracy: 0.1206\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1446 - accuracy: 0.1302 - val_loss: 0.5737 - val_accuracy: 0.1213\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1442 - accuracy: 0.1311 - val_loss: 0.5660 - val_accuracy: 0.1213\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1415 - accuracy: 0.1312 - val_loss: 0.5695 - val_accuracy: 0.1213\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1406 - accuracy: 0.1319 - val_loss: 0.5682 - val_accuracy: 0.1219\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1400 - accuracy: 0.1298 - val_loss: 0.5841 - val_accuracy: 0.1210\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1381 - accuracy: 0.1305 - val_loss: 0.5725 - val_accuracy: 0.1211\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1393 - accuracy: 0.1309 - val_loss: 0.5693 - val_accuracy: 0.1206\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1350 - accuracy: 0.1293 - val_loss: 0.5705 - val_accuracy: 0.1215\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1323 - accuracy: 0.1313 - val_loss: 0.5782 - val_accuracy: 0.1218\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1312 - accuracy: 0.1300 - val_loss: 0.5679 - val_accuracy: 0.1224\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1296 - accuracy: 0.1311 - val_loss: 0.5639 - val_accuracy: 0.1215\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1277 - accuracy: 0.1315 - val_loss: 0.5678 - val_accuracy: 0.1205\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1236 - accuracy: 0.1301 - val_loss: 0.5631 - val_accuracy: 0.1208\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1220 - accuracy: 0.1299 - val_loss: 0.5484 - val_accuracy: 0.1204\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1197 - accuracy: 0.1320 - val_loss: 0.5570 - val_accuracy: 0.1210\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1186 - accuracy: 0.1302 - val_loss: 0.5554 - val_accuracy: 0.1211\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1183 - accuracy: 0.1314 - val_loss: 0.5466 - val_accuracy: 0.1214\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1176 - accuracy: 0.1309 - val_loss: 0.5426 - val_accuracy: 0.1208\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1200 - accuracy: 0.1312 - val_loss: 0.5722 - val_accuracy: 0.1210\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1181 - accuracy: 0.1295 - val_loss: 0.5892 - val_accuracy: 0.1203\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1187 - accuracy: 0.1295 - val_loss: 0.5580 - val_accuracy: 0.1213\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1134 - accuracy: 0.1302 - val_loss: 0.5301 - val_accuracy: 0.1206\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1127 - accuracy: 0.1314 - val_loss: 0.5517 - val_accuracy: 0.1220\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1086 - accuracy: 0.1301 - val_loss: 0.5322 - val_accuracy: 0.1220\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1051 - accuracy: 0.1322 - val_loss: 0.5510 - val_accuracy: 0.1206\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1035 - accuracy: 0.1325 - val_loss: 0.5551 - val_accuracy: 0.1211\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1027 - accuracy: 0.1304 - val_loss: 0.5540 - val_accuracy: 0.1216\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1011 - accuracy: 0.1321 - val_loss: 0.5409 - val_accuracy: 0.1210\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0998 - accuracy: 0.1301 - val_loss: 0.5498 - val_accuracy: 0.1208\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0969 - accuracy: 0.1308 - val_loss: 0.5429 - val_accuracy: 0.1216\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0955 - accuracy: 0.1316 - val_loss: 0.5252 - val_accuracy: 0.1215\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0937 - accuracy: 0.1299 - val_loss: 0.5494 - val_accuracy: 0.1211\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0923 - accuracy: 0.1305 - val_loss: 0.5303 - val_accuracy: 0.1212\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0910 - accuracy: 0.1304 - val_loss: 0.5354 - val_accuracy: 0.1211\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0905 - accuracy: 0.1309 - val_loss: 0.5265 - val_accuracy: 0.1212\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0879 - accuracy: 0.1323 - val_loss: 0.5402 - val_accuracy: 0.1210\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0868 - accuracy: 0.1305 - val_loss: 0.5335 - val_accuracy: 0.1211\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0856 - accuracy: 0.1295 - val_loss: 0.5272 - val_accuracy: 0.1208\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0847 - accuracy: 0.1322 - val_loss: 0.5331 - val_accuracy: 0.1212\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0855 - accuracy: 0.1325 - val_loss: 0.5483 - val_accuracy: 0.1206\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0910 - accuracy: 0.1319 - val_loss: 0.5497 - val_accuracy: 0.1206\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0894 - accuracy: 0.1305 - val_loss: 0.5728 - val_accuracy: 0.1196\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0871 - accuracy: 0.1295 - val_loss: 0.5460 - val_accuracy: 0.1212\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0887 - accuracy: 0.1299 - val_loss: 0.5880 - val_accuracy: 0.1212\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0935 - accuracy: 0.1308 - val_loss: 0.5429 - val_accuracy: 0.1213\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0831 - accuracy: 0.1300 - val_loss: 0.5301 - val_accuracy: 0.1203\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0809 - accuracy: 0.1333 - val_loss: 0.5265 - val_accuracy: 0.1213\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0774 - accuracy: 0.1299 - val_loss: 0.5376 - val_accuracy: 0.1213\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0769 - accuracy: 0.1298 - val_loss: 0.5324 - val_accuracy: 0.1214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27ba8f54520>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1186 - accuracy: 0.1302 - val_loss: 0.5554 - val_accuracy: 0.1211\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1183 - accuracy: 0.1314 - val_loss: 0.5466 - val_accuracy: 0.1214\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1176 - accuracy: 0.1309 - val_loss: 0.5426 - val_accuracy: 0.1208\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1200 - accuracy: 0.1312 - val_loss: 0.5722 - val_accuracy: 0.1210\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1181 - accuracy: 0.1295 - val_loss: 0.5892 - val_accuracy: 0.1203\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1187 - accuracy: 0.1295 - val_loss: 0.5580 - val_accuracy: 0.1213\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1134 - accuracy: 0.1302 - val_loss: 0.5301 - val_accuracy: 0.1206\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1127 - accuracy: 0.1314 - val_loss: 0.5517 - val_accuracy: 0.1220\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1086 - accuracy: 0.1301 - val_loss: 0.5322 - val_accuracy: 0.1220\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1051 - accuracy: 0.1322 - val_loss: 0.5510 - val_accuracy: 0.1206\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1035 - accuracy: 0.1325 - val_loss: 0.5551 - val_accuracy: 0.1211\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1027 - accuracy: 0.1304 - val_loss: 0.5540 - val_accuracy: 0.1216\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1011 - accuracy: 0.1321 - val_loss: 0.5409 - val_accuracy: 0.1210\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0998 - accuracy: 0.1301 - val_loss: 0.5498 - val_accuracy: 0.1208\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0969 - accuracy: 0.1308 - val_loss: 0.5429 - val_accuracy: 0.1216\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0955 - accuracy: 0.1316 - val_loss: 0.5252 - val_accuracy: 0.1215\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0937 - accuracy: 0.1299 - val_loss: 0.5494 - val_accuracy: 0.1211\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0923 - accuracy: 0.1305 - val_loss: 0.5303 - val_accuracy: 0.1212\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0910 - accuracy: 0.1304 - val_loss: 0.5354 - val_accuracy: 0.1211\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0905 - accuracy: 0.1309 - val_loss: 0.5265 - val_accuracy: 0.1212\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0879 - accuracy: 0.1323 - val_loss: 0.5402 - val_accuracy: 0.1210\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0868 - accuracy: 0.1305 - val_loss: 0.5335 - val_accuracy: 0.1211\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0856 - accuracy: 0.1295 - val_loss: 0.5272 - val_accuracy: 0.1208\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.0847 - accuracy: 0.1322 - val_loss: 0.5331 - val_accuracy: 0.1212\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0855 - accuracy: 0.1325 - val_loss: 0.5483 - val_accuracy: 0.1206\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0910 - accuracy: 0.1319 - val_loss: 0.5497 - val_accuracy: 0.1206\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0894 - accuracy: 0.1305 - val_loss: 0.5728 - val_accuracy: 0.1196\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0871 - accuracy: 0.1295 - val_loss: 0.5460 - val_accuracy: 0.1212\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0887 - accuracy: 0.1299 - val_loss: 0.5880 - val_accuracy: 0.1212\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0935 - accuracy: 0.1308 - val_loss: 0.5429 - val_accuracy: 0.1213\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0831 - accuracy: 0.1300 - val_loss: 0.5301 - val_accuracy: 0.1203\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0809 - accuracy: 0.1333 - val_loss: 0.5265 - val_accuracy: 0.1213\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0774 - accuracy: 0.1299 - val_loss: 0.5376 - val_accuracy: 0.1213\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0769 - accuracy: 0.1298 - val_loss: 0.5324 - val_accuracy: 0.1214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27ba8f54520>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [encoder_input_seq, decoder_input_seq],\n",
    "    decoder_target_seq,\n",
    "    batch_size=64,\n",
    "    epochs=150,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff4eaf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]  # same as Input(shape=(None,))\n",
    "encoder_lstm1 = model.get_layer('encoder_lstm1')\n",
    "encoder_lstm2 = model.get_layer('encoder_lstm2')\n",
    "\n",
    "# Apply stacked LSTM layers\n",
    "encoder_output1, _, _ = encoder_lstm1(encoder_embedding)\n",
    "_, state_h, state_c = encoder_lstm2(encoder_output1)\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "abdb0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820eaba-44d9-4cd6-a342-a0463830efa2",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d68b4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,), name='decoder_inputs_infer')\n",
    "\n",
    "# Decoder state inputs (for 2 LSTM layers)\n",
    "decoder_state_input_h1 = Input(shape=(lstm_units,), name='decoder_h1')\n",
    "decoder_state_input_c1 = Input(shape=(lstm_units,), name='decoder_c1')\n",
    "decoder_state_input_h2 = Input(shape=(lstm_units,), name='decoder_h2')\n",
    "decoder_state_input_c2 = Input(shape=(lstm_units,), name='decoder_c2')\n",
    "decoder_states_inputs = [decoder_state_input_h1, decoder_state_input_c1,\n",
    "                         decoder_state_input_h2, decoder_state_input_c2]\n",
    "\n",
    "# Get the layers from the trained model\n",
    "decoder_embedding_layer = model.get_layer('decoder_embedding')\n",
    "decoder_lstm1 = model.get_layer('decoder_lstm1')\n",
    "decoder_lstm2 = model.get_layer('decoder_lstm2')\n",
    "decoder_dense = model.get_layer('decoder_dense')\n",
    "\n",
    "# Reuse the layers with new inputs\n",
    "embedded_inputs = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# First LSTM layer\n",
    "decoder_output1, state_h1, state_c1 = decoder_lstm1(\n",
    "    embedded_inputs, initial_state=[decoder_state_input_h1, decoder_state_input_c1]\n",
    ")\n",
    "\n",
    "# Second LSTM layer\n",
    "decoder_output2, state_h2, state_c2 = decoder_lstm2(\n",
    "    decoder_output1, initial_state=[decoder_state_input_h2, decoder_state_input_c2]\n",
    ")\n",
    "\n",
    "# Dense layer to get probabilities\n",
    "decoder_outputs = decoder_dense(decoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b5bc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs, state_h1, state_c1, state_h2, state_c2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76e551d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_index = {i: word for word, i in target_tokenizer.word_index.items()}\n",
    "sos_token = target_tokenizer.word_index['<sos>']\n",
    "eos_token = target_tokenizer.word_index['<eos>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdfd94-9816-477f-9df4-4bf5b2eaed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_to_words(number_str):\n",
    "    # Preprocess input number string\n",
    "    input_seq = input_tokenizer.texts_to_sequences([number_str])\n",
    "    input_seq = pad_sequences(input_seq, maxlen=max_encoder_seq_length, padding='post')\n",
    "\n",
    "    # Encode input to get initial states\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Unpack encoder states\n",
    "    state_h1, state_c1, state_h2, state_c2 = states_value[0], states_value[1], states_value[0], states_value[1]\n",
    "\n",
    "    # Prepare initial decoder input (<sos>)\n",
    "    target_seq = np.array([[sos_token]])\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h1, c1, h2, c2 = decoder_model.predict(\n",
    "            [target_seq, state_h1, state_c1, state_h2, state_c2]\n",
    "        )\n",
    "\n",
    "        # Get most likely token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = reverse_target_index.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word == '<eos>' or len(decoded_sentence.split()) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Update target_seq and states for next timestep\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        state_h1, state_c1, state_h2, state_c2 = h1, c1, h2, c2\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "381f88c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "fifty\n"
     ]
    }
   ],
   "source": [
    "print(number_to_words(\"50\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04b68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
